{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ƒê·ªçc file CSV\n",
        "# Ch·∫°y c√°c file ƒë·ªÉ s·ª≠ d·ª•ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh\n",
        "\n",
        "# DonHang (C√°i n√†y nh√°p. Tui ch·∫°y t√¨m sp ƒëi k√®m thui -- Tui l√†m l·ªôn :v)\n",
        "\n",
        "# Ch·ªß y·∫øu ch·∫°y c√°c file csv n√†y --> R·ªìi s·∫Ω in ra c√°c file csv\n",
        "\n",
        "# File csv g·ªëc --> File csv sau khi d·ª± ƒëo√°n gi√°\n",
        "# ChiPhiSPDuKien --> gia_ban_du_kien.csv\n",
        "# GiaBanCua1SoCuaHang --> gia_ban_du_kien_tu_CH_canh_tranh.csv\n",
        "# DuLieuBanHang --> gia_ban_du_kien_sau_4_thang.csv\n",
        "# KyNghi --> khuyen_mai_ngay_le.csv\n",
        "\n",
        "# --> T·ª´ ƒë√≥ l·∫•y c√°c file csv ƒë∆∞·ª£c t·∫°o ra\n",
        "# --> H·ªìi quy tuy·∫øn t√≠nh l·∫ßn n·ªØa ƒë·ªÉ ƒë∆∞a ra m·ª©c gi√° ph√π h·ª£p nh·∫•t"
      ],
      "metadata": {
        "id": "5yKk3avsY6K3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "================== T√¨m SP ƒëi k√®m ================"
      ],
      "metadata": {
        "id": "76s9I7jV5rQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad9_qo1CR3Lo"
      },
      "outputs": [],
      "source": [
        "# 1. ====================== B·∫±ng apriori t√¨m ra c√°c t·∫≠p ph·ªï bi·∫øn  =====================\n",
        "\n",
        "# T·ª´ file DonHang.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
        "df = pd.read_csv('DonHang.csv')\n",
        "\n",
        "# Hi·ªÉn th·ªã s·ªë ƒë∆°n h√†ng\n",
        "print(f\"S·ªë ƒë∆°n h√†ng: {df['MaDonHang'].nunique()}\")\n",
        "\n",
        "# T·∫°o ma tr·∫≠n ƒë∆°n h√†ng - s·∫£n ph·∫©m (1 n·∫øu c√≥ mua, 0 n·∫øu kh√¥ng)\n",
        "basket = df.groupby(['MaDonHang', 'Ma SP'])['SoLuong'].sum().unstack().fillna(0)\n",
        "basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# √Åp d·ª•ng thu·∫≠t to√°n Apriori ƒë·ªÉ t√¨m c√°c t·∫≠p ph·ªï bi·∫øn\n",
        "frequent_itemsets = apriori(basket, min_support=0.1, use_colnames=True)\n",
        "\n",
        "# Ki·ªÉm tra n·∫øu kh√¥ng t√¨m th·∫•y t·∫≠p ph·ªï bi·∫øn n√†o\n",
        "if frequent_itemsets.empty:\n",
        "    print(\"‚ùå Kh√¥ng t√¨m th·∫•y t·∫≠p ph·ªï bi·∫øn n√†o v·ªõi min_support ƒë√£ ch·ªçn.\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ C√°c t·∫≠p ph·ªï bi·∫øn:\")\n",
        "    print(frequent_itemsets)\n",
        "\n",
        "    # T·∫°o lu·∫≠t k·∫øt h·ª£p\n",
        "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "\n",
        "    print(\"\\n‚úÖ C√°c lu·∫≠t k·∫øt h·ª£p:\")\n",
        "    print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
        "\n",
        "    # === PH·∫¶N L·ªåC THEO S·∫¢N PH·∫®M ===\n",
        "    sp_target = input(\"\\nüîç Nh·∫≠p m√£ s·∫£n ph·∫©m c·∫ßn t√¨m (v√≠ d·ª•: SP01): \").strip()\n",
        "\n",
        "    # L·ªçc t·∫≠p ph·ªï bi·∫øn ch·ª©a s·∫£n ph·∫©m\n",
        "    related_itemsets = frequent_itemsets[frequent_itemsets['itemsets'].apply(lambda x: sp_target in x)]\n",
        "    print(f\"\\nüì¶ C√°c t·∫≠p ph·ªï bi·∫øn c√≥ ch·ª©a '{sp_target}':\")\n",
        "    print(related_itemsets)\n",
        "\n",
        "    # L·ªçc lu·∫≠t k·∫øt h·ª£p li√™n quan ƒë·∫øn s·∫£n ph·∫©m\n",
        "    related_rules = rules[\n",
        "        rules['antecedents'].apply(lambda x: sp_target in x) |\n",
        "        rules['consequents'].apply(lambda x: sp_target in x)\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nüîó C√°c lu·∫≠t k·∫øt h·ª£p li√™n quan ƒë·∫øn '{sp_target}':\")\n",
        "    print(related_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n"
      ],
      "metadata": {
        "id": "8PmiiSUKR-Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from collections import defaultdict\n",
        "\n",
        "# B∆∞·ªõc 1: ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
        "df = pd.read_csv('DonHang.csv')\n",
        "\n",
        "# B∆∞·ªõc 2: Gom nh√≥m s·∫£n ph·∫©m theo ƒë∆°n h√†ng th√†nh danh s√°ch giao d·ªãch\n",
        "donhang_dict = defaultdict(list)\n",
        "for _, row in df.iterrows():\n",
        "    donhang_dict[row['MaDonHang']].append(row['Ma SP'])\n",
        "\n",
        "transactions = list(donhang_dict.values())\n",
        "\n",
        "print(\"üõí Danh s√°ch c√°c giao d·ªãch:\")\n",
        "for t in transactions:\n",
        "    print(t)\n",
        "\n",
        "# B∆∞·ªõc 3: M√£ h√≥a d·ªØ li·ªáu giao d·ªãch\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# B∆∞·ªõc 4: √Åp d·ª•ng thu·∫≠t to√°n Apriori\n",
        "frequent_itemsets = apriori(df_encoded, min_support=0.1, use_colnames=True)\n",
        "\n",
        "# B∆∞·ªõc 5: In ra c√°c t·∫≠p ph·ªï bi·∫øn\n",
        "print(\"\\n‚úÖ C√°c t·∫≠p ph·ªï bi·∫øn t√¨m ƒë∆∞·ª£c:\")\n",
        "print(frequent_itemsets)\n",
        "\n",
        "# B∆∞·ªõc 6: L·ªçc theo MASP (m√£ s·∫£n ph·∫©m c·ª• th·ªÉ)\n",
        "masp = input(\"\\nüîç Nh·∫≠p m√£ s·∫£n ph·∫©m c·∫ßn t√¨m (v√≠ d·ª•: SP01): \").strip()\n",
        "related_itemsets = frequent_itemsets[frequent_itemsets['itemsets'].apply(lambda x: masp in x)]\n",
        "\n",
        "print(f\"\\nüì¶ C√°c t·∫≠p ph·ªï bi·∫øn c√≥ li√™n quan ƒë·∫øn '{masp}':\")\n",
        "print(related_itemsets)\n",
        "\n",
        "# B∆∞·ªõc 7: Sinh lu·∫≠t k·∫øt h·ª£p v√† l·ªçc theo MASP\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "\n",
        "related_rules = rules[\n",
        "    rules['antecedents'].apply(lambda x: masp in x) |\n",
        "    rules['consequents'].apply(lambda x: masp in x)\n",
        "]\n",
        "\n",
        "print(f\"\\nüîó C√°c lu·∫≠t k·∫øt h·ª£p li√™n quan ƒë·∫øn '{masp}':\")\n",
        "print(related_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n"
      ],
      "metadata": {
        "id": "_GfQwAGkR-AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " =============== D·ª± ƒëo√°n gi√° =================="
      ],
      "metadata": {
        "id": "3z8zIgZN5l7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ================= D·ªØ ƒëo√°n gi√° b√°n d·ª± ki·∫øn b·∫±ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh ==================\n",
        "\n",
        "# s·ª≠ d·ª•ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh ƒë·ªÉ d·ª± ƒëo√°n \"Gi√° B√°n D·ª± Ki·∫øn\" cho t·ª´ng s·∫£n ph·∫©m c√≥ trong file CSV\n",
        "\n",
        "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file ChiPhiSPDuKien_csv.csv"
      ],
      "metadata": {
        "id": "tnKTGceLR99x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1. ƒê·ªçc d·ªØ li·ªáu: ƒê·ªçc d·ªØ li·ªáu t·ª´ file ChiPhiSPDuKien_csv.csv.\n",
        "2. X·ª≠ l√Ω d·ªØ li·ªáu:\n",
        "3. ƒê·ªïi t√™n c·ªôt 'Khuyen Mai(%)' th√†nh 'Khuyen Mai (%)' v√† 'Danh Gia(%)' th√†nh 'Danh Gia (%)'.\n",
        "4. Ch·ªçn c√°c c·ªôt chi ph√≠, khuy·∫øn m√£i, ƒë√°nh gi√° l√†m features v√† 'Gia Ban Du Kien' l√†m target.\n",
        "5. Lo·∫°i b·ªè c√°c h√†ng c√≥ gi√° tr·ªã kh√¥ng ph·∫£i s·ªë trong c√°c c·ªôt features v√† target.\n",
        "6. Lo·∫°i b·ªè c√°c h√†ng c√≥ gi√° tr·ªã NaN sau khi chuy·ªÉn ƒë·ªïi ki·ªÉu s·ªë.\n",
        "7. Chia d·ªØ li·ªáu: Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán (80%) v√† t·∫≠p ki·ªÉm tra (20%).\n",
        "8. Hu·∫•n luy·ªán m√¥ h√¨nh: Hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh tr√™n t·∫≠p hu·∫•n luy·ªán.\n",
        "9. D·ª± ƒëo√°n: D·ª± ƒëo√°n 'Gia Ban Du Kien' cho to√†n b·ªô d·ªØ li·ªáu s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán.\n",
        "10. In k·∫øt qu·∫£: In ra DataFrame ch·ª©a 'Ma SP' v√† gi√° d·ª± ƒëo√°n.\n",
        "11. ƒê√°nh gi√° m√¥ h√¨nh: T√≠nh to√°n v√† in ra c√°c ch·ªâ s·ªë ƒë√°nh gi√° MSE, R-squared v√† MAE tr√™n t·∫≠p ki·ªÉm tra.\n",
        "12. Xu·∫•t file CSV: L∆∞u DataFrame k·∫øt qu·∫£ d·ª± ƒëo√°n v√†o file gia_ban_du_kien.csv."
      ],
      "metadata": {
        "id": "ob5sI4yV5VDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def xuat_file_csv(df, ten_file, index=False, encoding='utf-8'):\n",
        "    \"\"\"\n",
        "    H√†m xu·∫•t DataFrame ra file CSV.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame c·∫ßn xu·∫•t.\n",
        "        ten_file (str): T√™n file CSV (v√≠ d·ª•: 'output.csv').\n",
        "        index (bool, optional): C√≥ ghi index c·ªßa DataFrame v√†o file CSV kh√¥ng. M·∫∑c ƒë·ªãnh l√† False.\n",
        "        encoding (str, optional): M√£ h√≥a c·ªßa file CSV. M·∫∑c ƒë·ªãnh l√† 'utf-8'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df.to_csv(ten_file, index=index, encoding=encoding)\n",
        "        print(f\"ƒê√£ xu·∫•t th√†nh c√¥ng file CSV: '{ten_file}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"ƒê√£ x·∫£y ra l·ªói khi xu·∫•t file CSV: {e}\")\n",
        "\n",
        "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
        "try:\n",
        "    df_input = pd.read_csv('ChiPhiSPDuKien_csv.csv', encoding='utf-8')\n",
        "except FileNotFoundError:\n",
        "    print(\"Kh√¥ng t√¨m th·∫•y file ChiPhiSPDuKien_csv.csv. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.\")\n",
        "    exit()\n",
        "\n",
        "# ƒê·ªïi t√™n c·ªôt cho kh·ªõp (n·∫øu c·∫ßn)\n",
        "df_input.rename(columns={'Khuyen Mai(%)': 'Khuyen Mai (%)', 'Danh Gia(%)': 'Danh Gia (%)'}, inplace=True)\n",
        "\n",
        "# Ch·ªçn c√°c c·ªôt l√†m bi·∫øn ƒë·ªôc l·∫≠p (features) v√† bi·∫øn m·ª•c ti√™u (target)\n",
        "features = ['Chi Phi Nguyen Lieu', 'Chi Phi Nhan Cong', 'Chi Phi Van Hanh', 'Tong Chi Phi', 'Khuyen Mai (%)', 'Danh Gia (%)']\n",
        "target = 'Gia Ban Du Kien'\n",
        "\n",
        "# Lo·∫°i b·ªè c√°c h√†ng c√≥ gi√° tr·ªã kh√¥ng ph·∫£i s·ªë trong c√°c c·ªôt features\n",
        "for col in features:\n",
        "    df_input = df_input[pd.to_numeric(df_input[col], errors='coerce').notna()]\n",
        "\n",
        "# Chuy·ªÉn ƒë·ªïi c·ªôt target sang ki·ªÉu s·ªë\n",
        "df_input = df_input[pd.to_numeric(df_input[target], errors='coerce').notna()]\n",
        "df_input[target] = pd.to_numeric(df_input[target], errors='coerce')\n",
        "\n",
        "# Lo·∫°i b·ªè c√°c h√†ng c√≥ gi√° tr·ªã NaN sau khi chuy·ªÉn ƒë·ªïi\n",
        "df_input.dropna(subset=features + [target], inplace=True)\n",
        "\n",
        "X = df_input[features]\n",
        "y = df_input[target]\n",
        "\n",
        "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# D·ª± ƒëo√°n gi√° b√°n d·ª± ki·∫øn cho T·∫§T C·∫¢ s·∫£n ph·∫©m trong file\n",
        "y_pred_all = model.predict(X)\n",
        "\n",
        "# T·∫°o m·ªôt DataFrame m·ªõi ch·ª©a Ma SP v√† Gi√° B√°n D·ª± Ki·∫øn ƒë√£ d·ª± ƒëo√°n\n",
        "df_predicted = pd.DataFrame({'MaSP': df_input['Ma SP'], 'Gia Ban Du Kien': y_pred_all})\n",
        "\n",
        "# In ra DataFrame ch·ª©a Ma SP v√† gi√° d·ª± ƒëo√°n\n",
        "print(\"Gi√° b√°n d·ª± ki·∫øn d·ª± ƒëo√°n cho t·ª´ng s·∫£n ph·∫©m:\")\n",
        "print(df_predicted)\n",
        "\n",
        "# ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra\n",
        "y_pred_test = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred_test)\n",
        "print(f'Mean Squared Error tr√™n t·∫≠p ki·ªÉm tra: {mse:.2f}\\n')\n",
        "\n",
        "print(\"\\nƒê√°nh gi√° m√¥ h√¨nh:\")\n",
        "print(f\"Mean Squared Error (MSE) tr√™n t·∫≠p ki·ªÉm tra: {mse:.2f}\")\n",
        "\n",
        "# ƒê·ªÉ c√≥ th√™m c√°c ch·ªâ s·ªë ƒë√°nh gi√°, b·∫°n c√≥ th·ªÉ import th√™m c√°c h√†m t·ª´ sklearn.metrics\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_test)\n",
        "mae = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "print(f\"R-squared (R^2) tr√™n t·∫≠p ki·ªÉm tra: {r2:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE) tr√™n t·∫≠p ki·ªÉm tra: {mae:.2f}\")\n",
        "\n",
        "# S·ª≠ d·ª•ng h√†m xuat_file_csv ƒë·ªÉ xu·∫•t DataFrame k·∫øt qu·∫£ ra file CSV\n",
        "ten_file_xuat = 'gia_ban_du_kien.csv'\n",
        "xuat_file_csv(df_predicted, ten_file_xuat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngn9nFNIR97T",
        "outputId": "402372e2-fa11-48a3-ff33-09bf412250ac"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gi√° b√°n d·ª± ki·∫øn d·ª± ƒëo√°n cho t·ª´ng s·∫£n ph·∫©m:\n",
            "    MaSP  Gia Ban Du Kien\n",
            "0   SP01             22.0\n",
            "1   SP02             17.0\n",
            "2   SP03             25.0\n",
            "3   SP04             21.0\n",
            "4   SP05             25.0\n",
            "5   SP06             22.0\n",
            "6   SP07             23.0\n",
            "7   SP08             12.0\n",
            "8   SP09             14.0\n",
            "9   SP10             12.0\n",
            "10  SP11             15.0\n",
            "11  SP12             13.0\n",
            "12  SP13             17.0\n",
            "13  SP14             19.0\n",
            "14  SP15             17.0\n",
            "15  SP16             19.0\n",
            "16  SP17             17.0\n",
            "17  SP18             21.0\n",
            "Mean Squared Error tr√™n t·∫≠p ki·ªÉm tra: 0.00\n",
            "\n",
            "\n",
            "ƒê√°nh gi√° m√¥ h√¨nh:\n",
            "Mean Squared Error (MSE) tr√™n t·∫≠p ki·ªÉm tra: 0.00\n",
            "R-squared (R^2) tr√™n t·∫≠p ki·ªÉm tra: 1.00\n",
            "Mean Absolute Error (MAE) tr√™n t·∫≠p ki·ªÉm tra: 0.00\n",
            "ƒê√£ xu·∫•t th√†nh c√¥ng file CSV: 'gia_ban_du_kien.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= Gi√° b√°n c·ªßa 1 s·ªë c·ª≠a h√†ng ƒê·ªêI TH·ª¶ C·∫†NH TRANH ================\n",
        "\n",
        "# ƒë·ªçc s·ªØ li·ªáu t·ª´ file GiaBanCua1SoCuaHang_csv.csv\n",
        "\n",
        "# s·ª≠ d·ª•ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh ƒë·ªÉ d·ª± ƒëo√°n \"Gi√° B√°n\" cho t·ª´ng s·∫£n ph·∫©m c√≥ trong file CSV\n"
      ],
      "metadata": {
        "id": "aoMwwIiOR93I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1. ƒê·ªçc d·ªØ li·ªáu: ƒê·ªçc d·ªØ li·ªáu t·ª´ file GiaBanCua1SoCuaHang_csv.csv.\n",
        "2. X·ª≠ l√Ω d·ªØ li·ªáu:\n",
        "3. Thay th·∫ø gi√° tr·ªã 'k' b·∫±ng NaN trong c·ªôt 'GiaBanCuaHang 20'.\n",
        "4. Chuy·ªÉn ƒë·ªïi c√°c c·ªôt gi√° sang ki·ªÉu s·ªë v√† lo·∫°i b·ªè c√°c h√†ng ch·ª©a NaN.\n",
        "5. Ch·ªçn features v√† target: Ch·ªçn 'GiaBanCuaHang 1' l√†m target v√† c√°c c·ªôt gi√° c√≤n l·∫°i l√†m features.\n",
        "6. Chia d·ªØ li·ªáu: Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra.\n",
        "7. Hu·∫•n luy·ªán m√¥ h√¨nh: Hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh.\n",
        "8. D·ª± ƒëo√°n: D·ª± ƒëo√°n gi√° b√°n ph√π h·ª£p cho t·∫•t c·∫£ c√°c s·∫£n ph·∫©m ƒë√£ l√†m s·∫°ch d·ª±a tr√™n m√¥ h√¨nh.\n",
        "9. ƒê√°nh gi√° m√¥ h√¨nh: T√≠nh to√°n MSE, R-squared v√† MAE tr√™n t·∫≠p ki·ªÉm tra v√† ƒë∆∞a ra m·ªôt ƒë√°nh gi√° s∆° b·ªô.\n",
        "10. Xu·∫•t file CSV: L∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n v√†o file gia_ban_du_kien_tu_CH_canh_tranh.csv"
      ],
      "metadata": {
        "id": "8KBdxzrf4Zj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "def xuat_file_csv(df, ten_file, index=False, encoding='utf-8'):\n",
        "    \"\"\"\n",
        "    H√†m xu·∫•t DataFrame ra file CSV.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame c·∫ßn xu·∫•t.\n",
        "        ten_file (str): T√™n file CSV (v√≠ d·ª•: 'output.csv').\n",
        "        index (bool, optional): C√≥ ghi index c·ªßa DataFrame v√†o file CSV kh√¥ng. M·∫∑c ƒë·ªãnh l√† False.\n",
        "        encoding (str, optional): M√£ h√≥a c·ªßa file CSV. M·∫∑c ƒë·ªãnh l√† 'utf-8'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df.to_csv(ten_file, index=index, encoding=encoding)\n",
        "        print(f\"ƒê√£ xu·∫•t th√†nh c√¥ng file CSV: '{ten_file}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"ƒê√£ x·∫£y ra l·ªói khi xu·∫•t file CSV: {e}\")\n",
        "\n",
        "# T√™n file CSV\n",
        "file_path = 'GiaBanCua1SoCuaHang_csv.csv'\n",
        "\n",
        "try:\n",
        "    # ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV v·ªõi d·∫•u ph√¢n c√°ch l√† d·∫•u ph·∫©y\n",
        "    df = pd.read_csv(file_path, sep=',')\n",
        "\n",
        "    # Thay th·∫ø gi√° tr·ªã 'k' trong c·ªôt 'GiaBanCuaHang 20' b·∫±ng NaN\n",
        "    df['GiaBanCuaHang 20'] = df['GiaBanCuaHang 20'].replace('k', pd.NA)\n",
        "\n",
        "    # Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ c√°c c·ªôt gi√° sang ki·ªÉu s·ªë (√©p bu·ªôc l·ªói th√†nh NaN)\n",
        "    gia_cua_hang_cols = [col for col in df.columns if col != 'MaSP']\n",
        "    for col in gia_cua_hang_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    df_cleaned = df.dropna()\n",
        "\n",
        "    if not df_cleaned.empty and len(gia_cua_hang_cols) > 1:\n",
        "        # Ch·ªçn c·ªôt m·ª•c ti√™u v√† c√°c features\n",
        "        target_col = 'GiaBanCuaHang 1'\n",
        "        feature_cols = [col for col in gia_cua_hang_cols if col != target_col]\n",
        "\n",
        "        X = df_cleaned[feature_cols]\n",
        "        y = df_cleaned[target_col]\n",
        "\n",
        "        # Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh\n",
        "        model = LinearRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # D·ª± ƒëo√°n \"Gi√° B√°n\" ph√π h·ª£p d·ª±a tr√™n gi√° c·ªßa t·∫•t c·∫£ c√°c ƒë·ªëi th·ªß\n",
        "        # Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng to√†n b·ªô d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch ƒë·ªÉ d·ª± ƒëo√°n\n",
        "        X_all = df_cleaned[feature_cols]\n",
        "        predicted_gia_ban = model.predict(X_all)\n",
        "\n",
        "        df_gia_ban_du_kien = pd.DataFrame({'MaSP': df_cleaned['MaSP'], 'GiaBanPhuHop': predicted_gia_ban})\n",
        "        print(\"\\nGi√° B√°n Ph√π H·ª£p D·ª± Ki·∫øn (d·ª±a tr√™n m√¥ h√¨nh h·ªìi quy):\")\n",
        "        print(df_gia_ban_du_kien)\n",
        "\n",
        "        # ƒê√°nh gi√° m√¥ h√¨nh (tr√™n t·∫≠p ki·ªÉm tra)\n",
        "        y_pred_test = model.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred_test)\n",
        "        r2 = r2_score(y_test, y_pred_test)\n",
        "        mae = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "        print(\"\\nƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra:\")\n",
        "        print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "        print(f'R-squared (R^2): {r2:.2f}')\n",
        "        print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
        "\n",
        "        # ƒê√°nh gi√° t·ªët/x·∫•u (mang t√≠nh t∆∞∆°ng ƒë·ªëi)\n",
        "        print(\"\\nƒê√°nh gi√° m√¥ h√¨nh:\")\n",
        "        if r2 > 0.7:\n",
        "            print(\"M√¥ h√¨nh c√≥ v·∫ª ph√π h·ª£p t·ªët v·ªõi d·ªØ li·ªáu (R-squared cao).\")\n",
        "        elif r2 > 0.5:\n",
        "            print(\"M√¥ h√¨nh ·ªü m·ª©c ch·∫•p nh·∫≠n ƒë∆∞·ª£c.\")\n",
        "        else:\n",
        "            print(\"M√¥ h√¨nh c√≥ th·ªÉ ch∆∞a ph√π h·ª£p t·ªët.\")\n",
        "\n",
        "        if mae < (y_test.max() - y_test.min()) / 10:  # ∆Ø·ªõc t√≠nh m·ªôt ng∆∞·ª°ng t∆∞∆°ng ƒë·ªëi\n",
        "            print(\"Sai s·ªë trung b√¨nh tuy·ªát ƒë·ªëi (MAE) t∆∞∆°ng ƒë·ªëi nh·ªè.\")\n",
        "        else:\n",
        "            print(\"Sai s·ªë trung b√¨nh tuy·ªát ƒë·ªëi (MAE) c√≥ th·ªÉ c·∫ßn ƒë∆∞·ª£c c·∫£i thi·ªán.\")\n",
        "\n",
        "        # Xu·∫•t DataFrame df_gia_ban_du_kien ra file CSV\n",
        "        ten_file_xuat = 'gia_ban_du_kien_tu_CH_canh_tranh.csv'\n",
        "        xuat_file_csv(df_gia_ban_du_kien, ten_file_xuat)\n",
        "\n",
        "    else:\n",
        "        print(\"\\nKh√¥ng ƒë·ªß d·ªØ li·ªáu ho·∫∑c c·ªôt ƒë·ªÉ th·ª±c hi·ªán h·ªìi quy.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Kh√¥ng t√¨m th·∫•y file: {file_path}. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n file v√† ƒë∆∞·ªùng d·∫´n.\")\n",
        "except Exception as e:\n",
        "    print(f\"ƒê√£ x·∫£y ra l·ªói: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IguMJxDhR90Z",
        "outputId": "68d23415-ddb1-4839-8d9f-1f0edd0a37fb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gi√° B√°n Ph√π H·ª£p D·ª± Ki·∫øn (d·ª±a tr√™n m√¥ h√¨nh h·ªìi quy):\n",
            "    MaSP  GiaBanPhuHop\n",
            "0   SP01     21.912284\n",
            "1   SP02     16.986384\n",
            "2   SP03     27.000000\n",
            "3   SP04     35.000000\n",
            "4   SP05     23.000000\n",
            "5   SP06     25.561616\n",
            "6   SP07     25.000000\n",
            "7   SP08     17.000000\n",
            "8   SP09     17.422507\n",
            "9   SP10     16.000000\n",
            "10  SP11     17.000000\n",
            "11  SP12     14.000000\n",
            "12  SP13     22.000000\n",
            "13  SP14     18.000000\n",
            "14  SP15     20.000000\n",
            "15  SP16     21.000000\n",
            "16  SP17     20.000000\n",
            "17  SP18     25.000000\n",
            "\n",
            "ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra:\n",
            "Mean Squared Error (MSE): 2.48\n",
            "R-squared (R^2): 0.81\n",
            "Mean Absolute Error (MAE): 1.45\n",
            "\n",
            "ƒê√°nh gi√° m√¥ h√¨nh:\n",
            "M√¥ h√¨nh c√≥ v·∫ª ph√π h·ª£p t·ªët v·ªõi d·ªØ li·ªáu (R-squared cao).\n",
            "Sai s·ªë trung b√¨nh tuy·ªát ƒë·ªëi (MAE) c√≥ th·ªÉ c·∫ßn ƒë∆∞·ª£c c·∫£i thi·ªán.\n",
            "ƒê√£ xu·∫•t th√†nh c√¥ng file CSV: 'gia_ban_du_kien_tu_CH_canh_tranh.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= S·ªë l∆∞·ª£ng kh√°ch mua b√°n s·∫£n ph·∫©m trong 4 th√°ng ================\n",
        "\n",
        "# ƒë·ªçc s·ªØ li·ªáu t·ª´ file DuLieuBanHang_csv.csv\n",
        "\n",
        "# s·ª≠ d·ª•ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh ƒë·ªÉ d·ª± ƒëo√°n \"Gi√° B√°n\" cho t·ª´ng s·∫£n ph·∫©m c√≥ trong file CSV\n"
      ],
      "metadata": {
        "id": "QLKLc5qOR9yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1. ƒê·ªçc d·ªØ li·ªáu: ƒê·ªçc d·ªØ li·ªáu t·ª´ file DuLieuBanHang_csv.csv.\n",
        "2. ƒê·ªïi t√™n c·ªôt: ƒê·ªïi t√™n c·ªôt 'SanPham' th√†nh 'MaSP' v√† 'SoLuongBan' th√†nh 'SoLuongBan'.\n",
        "3. Ch·ªçn features v√† target: Ch·ªçn 'SoLuongBan' l√†m feature duy nh·∫•t v√† 'GiaBan' l√†m target.\n",
        "4. D·ª± ƒëo√°n theo t·ª´ng s·∫£n ph·∫©m:\n",
        "5. L·∫∑p qua t·ª´ng s·∫£n ph·∫©m duy nh·∫•t ('MaSP').\n",
        "6. V·ªõi m·ªói s·∫£n ph·∫©m, n·∫øu c√≥ nhi·ªÅu h∆°n m·ªôt d√≤ng d·ªØ li·ªáu, n√≥ s·∫Ω hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh ri√™ng bi·ªát ƒë·ªÉ d·ª± ƒëo√°n 'GiaBan' d·ª±a tr√™n 'SoLuongBan'. Gi√° d·ª± ƒëo√°n ƒë∆∞·ª£c t√≠nh d·ª±a tr√™n s·ªë l∆∞·ª£ng b√°n trung b√¨nh c·ªßa s·∫£n ph·∫©m ƒë√≥.\n",
        "7. N·∫øu ch·ªâ c√≥ m·ªôt d√≤ng d·ªØ li·ªáu cho s·∫£n ph·∫©m, gi√° d·ª± ƒëo√°n s·∫Ω l√† gi√° b√°n th·ª±c t·∫ø c·ªßa d√≤ng ƒë√≥.\n",
        "8. N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu cho s·∫£n ph·∫©m, gi√° d·ª± ƒëo√°n s·∫Ω l√† None.\n",
        "9. In k·∫øt qu·∫£: In ra DataFrame ch·ª©a 'MaSP' v√† 'GiaBanDuDoan'.\n",
        "10. Xu·∫•t file CSV: L∆∞u k·∫øt qu·∫£ v√†o file gia_ban_du_kien_sau_4_thang.csv."
      ],
      "metadata": {
        "id": "yw7QHkS75C7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "\n",
        "# B·ªè qua UserWarning v√† FutureWarning\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "def xuat_file_csv(df, ten_file, index=False, encoding='utf-8'):\n",
        "    \"\"\"\n",
        "    H√†m xu·∫•t DataFrame ra file CSV.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame c·∫ßn xu·∫•t.\n",
        "        ten_file (str): T√™n file CSV (v√≠ d·ª•: 'output.csv').\n",
        "        index (bool, optional): C√≥ ghi index c·ªßa DataFrame v√†o file CSV kh√¥ng. M·∫∑c ƒë·ªãnh l√† False.\n",
        "        encoding (str, optional): M√£ h√≥a c·ªßa file CSV. M·∫∑c ƒë·ªãnh l√† 'utf-8'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df.to_csv(ten_file, index=index, encoding=encoding)\n",
        "        print(f\"ƒê√£ xu·∫•t th√†nh c√¥ng file CSV: '{ten_file}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"ƒê√£ x·∫£y ra l·ªói khi xu·∫•t file CSV: {e}\")\n",
        "\n",
        "# T√™n file CSV\n",
        "ten_file = 'DuLieuBanHang_csv.csv'\n",
        "\n",
        "try:\n",
        "    # ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
        "    df = pd.read_csv(ten_file)\n",
        "    df.rename(columns={'SanPham': 'MaSP', 'SoLuongBan': 'SoLuongBan'}, inplace=True)\n",
        "\n",
        "    # C√°c bi·∫øn ƒë·ªôc l·∫≠p (features) c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn gi√°\n",
        "    cac_cot_dau_vao = ['SoLuongBan']\n",
        "    cot_muc_tieu = 'GiaBan'\n",
        "\n",
        "    # T·∫°o DataFrame ƒë·ªÉ l∆∞u gi√° d·ª± ƒëo√°n cho t·ª´ng s·∫£n ph·∫©m\n",
        "    df_gia_du_doan = pd.DataFrame(columns=['MaSP', 'GiaBanDuDoan'])\n",
        "\n",
        "    # L·∫∑p qua t·ª´ng s·∫£n ph·∫©m duy nh·∫•t\n",
        "    for ma_sp in df['MaSP'].unique():\n",
        "        df_sp = df[df['MaSP'] == ma_sp].dropna(subset=cac_cot_dau_vao + [cot_muc_tieu])\n",
        "\n",
        "        if len(df_sp) > 1:\n",
        "            X = df_sp[cac_cot_dau_vao]\n",
        "            y = df_sp[cot_muc_tieu]\n",
        "\n",
        "            model = LinearRegression()\n",
        "            model.fit(X, y)\n",
        "\n",
        "            so_luong_ban_tb = df_sp['SoLuongBan'].mean()\n",
        "            gia_ban_du_doan = model.predict([[so_luong_ban_tb]])[0]\n",
        "\n",
        "            df_gia_du_doan = pd.concat([df_gia_du_doan, pd.DataFrame([{'MaSP': ma_sp, 'GiaBanDuDoan': gia_ban_du_doan}])], ignore_index=True)\n",
        "\n",
        "        elif not df_sp.empty:\n",
        "            gia_ban_thuc_te = df_sp['GiaBan'].iloc[0]\n",
        "            df_gia_du_doan = pd.concat([df_gia_du_doan, pd.DataFrame([{'MaSP': ma_sp, 'GiaBanDuDoan': gia_ban_thuc_te}])], ignore_index=True)\n",
        "        else:\n",
        "            df_gia_du_doan = pd.concat([df_gia_du_doan, pd.DataFrame([{'MaSP': ma_sp, 'GiaBanDuDoan': None}])], ignore_index=True)\n",
        "\n",
        "    print(\"\\nGi√° B√°n D·ª± ƒêo√°n (d·ª±a tr√™n h·ªìi quy tuy·∫øn t√≠nh theo t·ª´ng s·∫£n ph·∫©m):\")\n",
        "    print(df_gia_du_doan)\n",
        "\n",
        "    # Xu·∫•t DataFrame df_gia_du_doan ra file CSV\n",
        "    ten_file_xuat = 'gia_ban_du_kien_sau_4_thang.csv'\n",
        "    xuat_file_csv(df_gia_du_doan, ten_file_xuat)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Kh√¥ng t√¨m th·∫•y file: {ten_file}. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n file v√† ƒë∆∞·ªùng d·∫´n.\")\n",
        "except Exception as e:\n",
        "    print(f\"ƒê√£ x·∫£y ra l·ªói: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6hsWjqMR9qs",
        "outputId": "cdb1fc73-f0fd-40da-9054-3e07da04b83f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gi√° B√°n D·ª± ƒêo√°n (d·ª±a tr√™n h·ªìi quy tuy·∫øn t√≠nh theo t·ª´ng s·∫£n ph·∫©m):\n",
            "    MaSP  GiaBanDuDoan\n",
            "0   SP01     21.933333\n",
            "1   SP02     18.083333\n",
            "2   SP03     24.166667\n",
            "3   SP04     20.933333\n",
            "4   SP05     24.933333\n",
            "5   SP06     23.850000\n",
            "6   SP07     23.700000\n",
            "7   SP08     17.683333\n",
            "8   SP09     18.150000\n",
            "9   SP10     18.450000\n",
            "10  SP11     20.683333\n",
            "11  SP12     17.533333\n",
            "12  SP13     23.066667\n",
            "13  SP14     22.766667\n",
            "14  SP15     23.066667\n",
            "15  SP16     23.150000\n",
            "16  SP17     22.300000\n",
            "17  SP18     20.550000\n",
            "ƒê√£ xu·∫•t th√†nh c√¥ng file CSV: 'gia_ban_du_kien_sau_4_thang.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ƒê∆∞a ra ƒë√°nh gi√° m√¥ h√¨nh ---- Nh√°p ----\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import warnings\n",
        "\n",
        "# B·ªè qua UserWarning v√† FutureWarning\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "def xuat_file_csv(df, ten_file, index=False, encoding='utf-8'):\n",
        "    \"\"\"\n",
        "    H√†m xu·∫•t DataFrame ra file CSV.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame c·∫ßn xu·∫•t.\n",
        "        ten_file (str): T√™n file CSV (v√≠ d·ª•: 'output.csv').\n",
        "        index (bool, optional): C√≥ ghi index c·ªßa DataFrame v√†o file CSV kh√¥ng. M·∫∑c ƒë·ªãnh l√† False.\n",
        "        encoding (str, optional): M√£ h√≥a c·ªßa file CSV. M·∫∑c ƒë·ªãnh l√† 'utf-8'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df.to_csv(ten_file, index=index, encoding=encoding)\n",
        "        print(f\"ƒê√£ xu·∫•t th√†nh c√¥ng file CSV: '{ten_file}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"ƒê√£ x·∫£y ra l·ªói khi xu·∫•t file CSV: {e}\")\n",
        "\n",
        "def danh_gia_mo_hinh(y_true, y_pred, ma_sp):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    print(f\"\\nƒê√°nh gi√° m√¥ h√¨nh cho s·∫£n ph·∫©m {ma_sp}:\")\n",
        "    print(f\"  Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"  R-squared (R^2): {r2:.2f}\")\n",
        "    print(f\"  Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    if r2 > 0.7:\n",
        "        print(\"  M√¥ h√¨nh c√≥ v·∫ª ph√π h·ª£p t·ªët.\")\n",
        "    elif r2 > 0.5:\n",
        "        print(\"  M√¥ h√¨nh ·ªü m·ª©c ch·∫•p nh·∫≠n ƒë∆∞·ª£c.\")\n",
        "    else:\n",
        "        print(\"  M√¥ h√¨nh c√≥ th·ªÉ ch∆∞a ph√π h·ª£p t·ªët.\")\n",
        "\n",
        "# T√™n file CSV\n",
        "ten_file = 'DuLieuBanHang_csv.csv'\n",
        "\n",
        "try:\n",
        "    # ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
        "    df = pd.read_csv(ten_file)\n",
        "    df.rename(columns={'SanPham': 'MaSP', 'SoLuongBan': 'SoLuongBan'}, inplace=True)\n",
        "\n",
        "    # C√°c bi·∫øn ƒë·ªôc l·∫≠p (features) c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn gi√°\n",
        "    cac_cot_dau_vao = ['SoLuongBan']\n",
        "    cot_muc_tieu = 'GiaBan'\n",
        "\n",
        "    # T·∫°o DataFrame ƒë·ªÉ l∆∞u gi√° d·ª± ƒëo√°n cho t·ª´ng s·∫£n ph·∫©m\n",
        "    df_gia_du_doan = pd.DataFrame(columns=['MaSP', 'GiaBanDuDoan'])\n",
        "\n",
        "    # L·∫∑p qua t·ª´ng s·∫£n ph·∫©m duy nh·∫•t\n",
        "    for ma_sp in df['MaSP'].unique():\n",
        "        df_sp = df[df['MaSP'] == ma_sp].dropna(subset=cac_cot_dau_vao + [cot_muc_tieu])\n",
        "\n",
        "        if len(df_sp) > 5:  # C·∫ßn √≠t nh·∫•t v√†i ƒëi·ªÉm d·ªØ li·ªáu ƒë·ªÉ chia train/test c√≥ √Ω nghƒ©a\n",
        "            X = df_sp[cac_cot_dau_vao]\n",
        "            y = df_sp[cot_muc_tieu]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            model = LinearRegression()\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            y_pred = model.predict(X_test)\n",
        "            danh_gia_mo_hinh(y_test, y_pred, ma_sp)\n",
        "\n",
        "            so_luong_ban_tb = df_sp['SoLuongBan'].mean()\n",
        "            gia_ban_du_doan = model.predict([[so_luong_ban_tb]])[0]\n",
        "            df_gia_du_doan = pd.concat([df_gia_du_doan, pd.DataFrame([{'MaSP': ma_sp, 'GiaBanDuDoan': gia_ban_du_doan}])], ignore_index=True)\n",
        "\n",
        "        elif not df_sp.empty:\n",
        "            gia_ban_thuc_te = df_sp['GiaBan'].iloc[0]\n",
        "            df_gia_du_doan = pd.concat([df_gia_du_doan, pd.DataFrame([{'MaSP': ma_sp, 'GiaBanDuDoan': gia_ban_thuc_te}])], ignore_index=True)\n",
        "        else:\n",
        "            df_gia_du_doan = pd.concat([df_gia_du_doan, pd.DataFrame([{'MaSP': ma_sp, 'GiaBanDuDoan': None}])], ignore_index=True)\n",
        "\n",
        "    print(\"\\nGi√° B√°n D·ª± ƒêo√°n (d·ª±a tr√™n h·ªìi quy tuy·∫øn t√≠nh theo t·ª´ng s·∫£n ph·∫©m):\")\n",
        "    print(df_gia_du_doan)\n",
        "\n",
        "    # Xu·∫•t DataFrame df_gia_du_doan ra file CSV\n",
        "    ten_file_xuat = 'gia_ban_du_kien_sau_4_thang.csv'\n",
        "    xuat_file_csv(df_gia_du_doan, ten_file_xuat)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Kh√¥ng t√¨m th·∫•y file: {ten_file}. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n file v√† ƒë∆∞·ªùng d·∫´n.\")\n",
        "except Exception as e:\n",
        "    print(f\"ƒê√£ x·∫£y ra l·ªói: {e}\")"
      ],
      "metadata": {
        "id": "D3xpsPZVH6t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================= ƒê∆∞a ra m·ª©c % khuy·∫øn m√£i v√†o c√°c ng√†y L·ªÖ ================\n",
        "\n",
        "# ƒë·ªçc d·ªØ li·ªáu t·ª´ file KyNghi.csv\n",
        "\n",
        "# s·ª≠ d·ª•ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh ƒë·ªÉ d·ª± ƒëo√°n \"% khuy·∫øn m√£i\" cho c√°c ng√†y l·ªÖ c√≥ trong file CSV\n"
      ],
      "metadata": {
        "id": "dBp-iRveu67K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# ƒê·ªçc file CSV\n",
        "try:\n",
        "    df = pd.read_csv('KyNghi.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"L·ªói: Kh√¥ng t√¨m th·∫•y file KyNghi.csv. Vui l√≤ng ƒë·∫£m b·∫£o file t·ªìn t·∫°i trong th∆∞ m·ª•c l√†m vi·ªác.\")\n",
        "    exit()\n",
        "\n",
        "# H√†m t·∫°o c·ªôt 'Ph·∫ßn trƒÉm khuy·∫øn m√£i' d·ª±a tr√™n quy t·∫Øc cho ng√†y l·ªÖ\n",
        "def get_promotion(row):\n",
        "    if pd.notnull(row['Ngay le']) and row['Ngay le'] != 'NULL':\n",
        "        promotion = (\n",
        "            row['Cuoi tuan'] * 2 +  # Th√™m % n·∫øu cu·ªëi tu·∫ßn\n",
        "            row['Nghi hoc'] * 3 +    # Th√™m % n·∫øu ngh·ªâ h·ªçc\n",
        "            (row['Nhiet do TB'] - 25) * 0.3 + # Th√™m % theo nhi·ªát ƒë·ªô (tr√™n 25)\n",
        "            row['Ngoai troi'] * 5      # Th√™m % theo ho·∫°t ƒë·ªông ngo√†i tr·ªùi\n",
        "        )\n",
        "        return max(0, promotion) # ƒê·∫£m b·∫£o khuy·∫øn m√£i kh√¥ng √¢m\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "df['Ph·∫ßn trƒÉm khuy·∫øn m√£i'] = df.apply(get_promotion, axis=1)\n",
        "\n",
        "# Chuy·ªÉn ƒë·ªïi bi·∫øn 'Ngay le' th√†nh bi·∫øn s·ªë (cho m√¥ h√¨nh)\n",
        "df['La_Ngay_Le'] = df['Ngay le'].apply(lambda x: 1 if pd.notnull(x) and x != 'NULL' else 0)\n",
        "\n",
        "# Ch·ªçn c√°c bi·∫øn ƒë·ªôc l·∫≠p v√† bi·∫øn m·ª•c ti√™u\n",
        "features = ['Cuoi tuan', 'Nghi hoc', 'Nhiet do TB', 'Ngoai troi', 'La_Ngay_Le']\n",
        "target = 'Ph·∫ßn trƒÉm khuy·∫øn m√£i'\n",
        "\n",
        "# Lo·∫°i b·ªè c√°c d√≤ng c√≥ gi√° tr·ªã NaN trong c√°c c·ªôt li√™n quan\n",
        "df_cleaned = df.dropna(subset=features + [target])\n",
        "\n",
        "X = df_cleaned[features]\n",
        "y = df_cleaned[target]\n",
        "\n",
        "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh tr√™n TO√ÄN B·ªò d·ªØ li·ªáu hu·∫•n luy·ªán\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# D·ª± ƒëo√°n ph·∫ßn trƒÉm khuy·∫øn m√£i tr√™n t·∫≠p ki·ªÉm tra\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'\\nMean Squared Error tr√™n t·∫≠p ki·ªÉm tra: {mse}')\n",
        "\n",
        "# ƒê√°nh gi√° m√¥ h√¨nh (d·ª±a tr√™n MSE)\n",
        "print(\"\\nƒê√°nh gi√° m√¥ h√¨nh (d·ª±a tr√™n MSE):\")\n",
        "if mse < 2:\n",
        "    print(\"M√¥ h√¨nh c√≥ v·∫ª ƒë·∫°t chu·∫©n t·ªët.\")\n",
        "elif mse < 5:\n",
        "    print(\"M√¥ h√¨nh ·ªü m·ª©c ch·∫•p nh·∫≠n ƒë∆∞·ª£c.\")\n",
        "else:\n",
        "    print(\"M√¥ h√¨nh c√≥ th·ªÉ ch∆∞a ƒë·∫°t chu·∫©n.\")\n",
        "\n",
        "# L·ªçc ra k·∫øt qu·∫£ d·ª± ƒëo√°n ch·ªâ cho c√°c ng√†y l·ªÖ (Ngay le kh√°c NULL) tr√™n t·∫≠p D·ªÆ LI·ªÜU G·ªêC ƒë√£ l√†m s·∫°ch\n",
        "df_le_results = df_cleaned[df_cleaned['Ngay le'].notna() & (df_cleaned['Ngay le'] != 'NULL')].copy()\n",
        "df_le_results['Ph·∫ßn trƒÉm khuy·∫øn m√£i d·ª± ƒëo√°n'] = model.predict(df_le_results[features])\n",
        "\n",
        "print(\"\\nK·∫øt qu·∫£ d·ª± ƒëo√°n ph·∫ßn trƒÉm khuy·∫øn m√£i cho c√°c ng√†y l·ªÖ:\")\n",
        "print(df_le_results[['Ngay Thang', 'Ngay le', 'Ph·∫ßn trƒÉm khuy·∫øn m√£i', 'Ph·∫ßn trƒÉm khuy·∫øn m√£i d·ª± ƒëo√°n']])\n",
        "\n",
        "# Xu·∫•t k·∫øt qu·∫£ d·ª± ƒëo√°n cho ng√†y l·ªÖ ra file CSV\n",
        "output_file = 'khuyen_mai_ngay_le.csv'\n",
        "df_le_results[['Ngay Thang', 'Ngay le', 'Ph·∫ßn trƒÉm khuy·∫øn m√£i d·ª± ƒëo√°n']].to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"\\nƒê√£ xu·∫•t k·∫øt qu·∫£ d·ª± ƒëo√°n khuy·∫øn m√£i cho c√°c ng√†y l·ªÖ ra file: {output_file}\")\n",
        "\n",
        "print(\"\\nC√°c h·ªá s·ªë c·ªßa m√¥ h√¨nh h·ªìi quy (hu·∫•n luy·ªán tr√™n to√†n b·ªô d·ªØ li·ªáu):\")\n",
        "coefficients = pd.DataFrame({'Feature': features, 'Coefficient': model.coef_})\n",
        "print(coefficients)\n",
        "print(f\"\\nIntercept: {model.intercept_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpNIb68Qmngj",
        "outputId": "25ffb3c7-66e5-4c59-f1d7-ab71ba7f9733"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Squared Error tr√™n t·∫≠p ki·ªÉm tra: 0.2443056088221271\n",
            "\n",
            "ƒê√°nh gi√° m√¥ h√¨nh (d·ª±a tr√™n MSE):\n",
            "M√¥ h√¨nh c√≥ v·∫ª ƒë·∫°t chu·∫©n t·ªët.\n",
            "\n",
            "K·∫øt qu·∫£ d·ª± ƒëo√°n ph·∫ßn trƒÉm khuy·∫øn m√£i cho c√°c ng√†y l·ªÖ:\n",
            "     Ngay Thang                        Ngay le  Ph·∫ßn trƒÉm khuy·∫øn m√£i  \\\n",
            "0    2023-01-01                 Tet duong lich                   8.3   \n",
            "19   2023-01-20                 Tet Nguyen Dan                   6.3   \n",
            "20   2023-01-21                 Tet Nguyen Dan                   8.3   \n",
            "21   2023-01-22                 Tet Nguyen Dan                   8.3   \n",
            "22   2023-01-23                 Tet Nguyen Dan                   6.3   \n",
            "23   2023-01-24                 Tet Nguyen Dan                   6.3   \n",
            "66   2023-03-08                 Quoc te Phu nu                   3.3   \n",
            "107  2023-04-18              Gio to Hung Vuong                   8.3   \n",
            "118  2023-04-29  Giai phong mien Nam (nghi bu)                   8.3   \n",
            "119  2023-04-30            Giai phong mien Nam                   8.3   \n",
            "120  2023-05-01               Quoc te Lao dong                   7.7   \n",
            "151  2023-06-01              Quoc te thieu nhi                   7.7   \n",
            "244  2023-09-02           Quoc khanh (nghi bu)                   9.7   \n",
            "292  2023-10-20                Phu nu Viet Nam                   3.3   \n",
            "323  2023-11-20              Nha giao Viet Nam                   3.3   \n",
            "355  2023-12-22         Ngay thanh lap Q?ND VN                   3.3   \n",
            "365  2024-01-01                 Tet duong lich                   7.4   \n",
            "403  2024-02-08                 Tet Nguyen Dan                   6.8   \n",
            "404  2024-02-09                 Tet Nguyen Dan                   7.1   \n",
            "405  2024-02-10                 Tet Nguyen Dan                   8.8   \n",
            "406  2024-02-11       Tet Nguyen Dan (nghi bu)                  10.3   \n",
            "407  2024-02-12       Tet Nguyen Dan (nghi bu)                   6.8   \n",
            "432  2024-03-08                 Quoc te Phu nu                   5.2   \n",
            "473  2024-04-18              Gio to Hung Vuong                   6.6   \n",
            "485  2024-04-30            Giai phong mien Nam                   5.4   \n",
            "486  2024-05-01               Quoc te lao dong                   5.1   \n",
            "517  2024-06-01              Quoc te thieu nhi                   7.1   \n",
            "610  2024-09-02                     Quoc khanh                   6.8   \n",
            "658  2024-10-20                Phu nu Viet Nam                   8.6   \n",
            "689  2024-11-20              Nha giao Viet Nam                   4.9   \n",
            "721  2024-12-22         Ngay thanh lap Q?ND VN                   7.3   \n",
            "\n",
            "     Ph·∫ßn trƒÉm khuy·∫øn m√£i d·ª± ƒëo√°n  \n",
            "0                        6.926032  \n",
            "19                       6.787062  \n",
            "20                       6.926032  \n",
            "21                       6.926032  \n",
            "22                       6.787062  \n",
            "23                       6.787062  \n",
            "66                       6.816269  \n",
            "107                      6.926032  \n",
            "118                      6.926032  \n",
            "119                      6.926032  \n",
            "120                      6.841858  \n",
            "151                      6.841858  \n",
            "244                      6.980828  \n",
            "292                      6.816269  \n",
            "323                      6.816269  \n",
            "355                      6.816269  \n",
            "365                      7.071092  \n",
            "403                      7.079738  \n",
            "404                      7.075415  \n",
            "405                      7.218708  \n",
            "406                      7.197093  \n",
            "407                      7.079738  \n",
            "432                      6.727943  \n",
            "473                      6.782739  \n",
            "485                      6.800031  \n",
            "486                      6.804354  \n",
            "517                      6.943324  \n",
            "610                      6.854827  \n",
            "658                      6.921709  \n",
            "689                      6.732266  \n",
            "721                      6.790501  \n",
            "\n",
            "ƒê√£ xu·∫•t k·∫øt qu·∫£ d·ª± ƒëo√°n khuy·∫øn m√£i cho c√°c ng√†y l·ªÖ ra file: khuyen_mai_ngay_le.csv\n",
            "\n",
            "C√°c h·ªá s·ªë c·ªßa m√¥ h√¨nh h·ªìi quy (hu·∫•n luy·ªán tr√™n to√†n b·ªô d·ªØ li·ªáu):\n",
            "       Feature  Coefficient\n",
            "0    Cuoi tuan     0.138970\n",
            "1     Nghi hoc    -0.029207\n",
            "2  Nhiet do TB    -0.004323\n",
            "3   Ngoai troi     0.677652\n",
            "4   La_Ngay_Le     6.851696\n",
            "\n",
            "Intercept: -0.3296175570736601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C·ªôt \"Ph·∫ßn trƒÉm khuy·∫øn m√£i d·ª± ƒëo√°n\" ch·ª©a k·∫øt qu·∫£ d·ª± ƒëo√°n m·ª©c ph·∫ßn trƒÉm khuy·∫øn m√£i cho t·ª´ng ng√†y\n",
        "(bao g·ªìm c·∫£ ng√†y l·ªÖ v√† ng√†y th∆∞·ªùng) m√† m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh ƒë√£ ƒë∆∞a ra sau khi ƒë∆∞·ª£c hu·∫•n luy·ªán.\n",
        "\n",
        "M√¥ h√¨nh n√†y ƒë√£ c·ªë g·∫Øng h·ªçc m·ªëi quan h·ªá gi·ªØa c√°c features (Cuoi tuan, Nghi hoc, Nhiet do TB, Ngoai troi, La_Ngay_Le)\n",
        "v√† target (c·ªôt \"Ph·∫ßn trƒÉm khuy·∫øn m√£i\" m√† ch√∫ng ta ƒë√£ t·∫°o d·ª±a tr√™n quy t·∫Øc cho ng√†y l·ªÖ)."
      ],
      "metadata": {
        "id": "yA86V3AIublb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======= CH·ªêT GI√Å B√ÅN PH√ô H·ª¢P NH·∫§T CHO SP ========\n",
        "# 1. ƒê·ªçc d·ªØ li·ªáu t·ª´ c·∫£ ba file CSV v√†o c√°c DataFrame.\n",
        "# 2. G·ªôp c√°c DataFrame n√†y l·∫°i v·ªõi nhau d·ª±a tr√™n c·ªôt 'MaSP'.\n",
        "# 3. Ch·ªçn c√°c c·ªôt gi√° d·ª± ƒëo√°n l√†m bi·∫øn ƒë·ªôc l·∫≠p (features) v√† m·ªôt trong s·ªë ch√∫ng (v√≠ d·ª•, gi√° t·ª´ gia_ban_du_kien.csv) l√†m bi·∫øn m·ª•c ti√™u ban ƒë·∫ßu ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.\n",
        "# 4. Hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh.\n",
        "# 5. S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n m·ªôt m·ª©c gi√° m·ªõi, c√≥ th·ªÉ d·ª±a tr√™n ch√≠nh c√°c features ƒë√≥."
      ],
      "metadata": {
        "id": "cEZlRFsawwEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# 1. ƒê·ªçc d·ªØ li·ªáu t·ª´ c√°c file CSV\n",
        "try:\n",
        "    df_gia_ban = pd.read_csv('gia_ban_du_kien.csv')\n",
        "    df_canh_tranh = pd.read_csv('gia_ban_du_kien_tu_CH_canh_tranh.csv')\n",
        "    df_4_thang = pd.read_csv('gia_ban_du_kien_sau_4_thang.csv')\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Kh√¥ng t√¨m th·∫•y m·ªôt ho·∫∑c nhi·ªÅu file CSV: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ƒê·ªïi t√™n c·ªôt ƒë·ªÉ d·ªÖ qu·∫£n l√Ω\n",
        "df_canh_tranh = df_canh_tranh.rename(columns={'GiaBanPhuHop': 'GiaBan_CanhTranh'})\n",
        "df_4_thang = df_4_thang.rename(columns={'GiaBanDuDoan': 'GiaBan_4Thang'})\n",
        "df_gia_ban = df_gia_ban.rename(columns={'Gia Ban Du Kien': 'GiaBan_ChiPhi'})\n",
        "\n",
        "# 2. G·ªôp c√°c DataFrame l·∫°i v·ªõi nhau d·ª±a tr√™n c·ªôt 'MaSP'\n",
        "df_merged = pd.merge(df_gia_ban[['MaSP', 'GiaBan_ChiPhi']], df_canh_tranh[['MaSP', 'GiaBan_CanhTranh']], on='MaSP', how='outer')\n",
        "df_merged = pd.merge(df_merged, df_4_thang[['MaSP', 'GiaBan_4Thang']], on='MaSP', how='outer')\n",
        "\n",
        "# 3. Ch·ªçn t·∫•t c·∫£ c√°c c·ªôt gi√° d·ª± ƒëo√°n l√†m features\n",
        "features = ['GiaBan_ChiPhi', 'GiaBan_CanhTranh', 'GiaBan_4Thang']\n",
        "\n",
        "# T·∫°o m·ªôt c·ªôt m·ª•c ti√™u gi·∫£ ƒë·ªãnh (v√≠ d·ª•, trung b√¨nh c·ªßa c√°c gi√°) ƒë·ªÉ hu·∫•n luy·ªán\n",
        "df_merged['GiaTriTrungBinh'] = df_merged[features].mean(axis=1)\n",
        "target = 'GiaTriTrungBinh'\n",
        "\n",
        "# Lo·∫°i b·ªè c√°c h√†ng ch·ª©a NaN ·ªü c√°c c·ªôt features v√† target\n",
        "df_final = df_merged.dropna(subset=features + [target])\n",
        "\n",
        "# Chu·∫©n b·ªã d·ªØ li·ªáu cho m√¥ h√¨nh\n",
        "X = df_final[features]\n",
        "y = df_final[target]\n",
        "\n",
        "# 4. Hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# 5. S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n m·ª©c gi√° k·∫øt h·ª£p\n",
        "gia_ban_du_doan_cuoi = model.predict(X)\n",
        "\n",
        "# T·∫°o DataFrame k·∫øt qu·∫£\n",
        "df_result = pd.DataFrame({'MaSP': df_final['MaSP'], 'GiaBanDuDoan': gia_ban_du_doan_cuoi})\n",
        "\n",
        "# In k·∫øt qu·∫£\n",
        "print(\"\\nGi√° b√°n d·ª± ƒëo√°n cu·ªëi c√πng (d·ª±a tr√™n m√¥ h√¨nh h·ªìi quy t·ª´ t·∫•t c·∫£ c√°c gi√°):\")\n",
        "print(df_result)\n",
        "\n",
        "# T·∫°o n·ªôi dung file SQL\n",
        "sql_commands = \"-- B·∫£ng ch·ª©a gi√° b√°n d·ª± ƒëo√°n\\n\"\n",
        "sql_commands += \"CREATE TABLE IF NOT EXISTS gia_du_doan (\\n\"\n",
        "sql_commands += \"    MaSP TEXT PRIMARY KEY,\\n\"\n",
        "sql_commands += \"    GiaBanDuDoan REAL\\n\"\n",
        "sql_commands += \");\\n\\n\"\n",
        "\n",
        "sql_commands += \"-- X√≥a d·ªØ li·ªáu c≈© (n·∫øu c·∫ßn)\\n\"\n",
        "sql_commands += \"DELETE FROM gia_du_doan;\\n\\n\"\n",
        "\n",
        "sql_commands += \"-- Th√™m d·ªØ li·ªáu gi√° b√°n d·ª± ƒëo√°n\\n\"\n",
        "for index, row in df_result.iterrows():\n",
        "    sql_commands += f\"INSERT INTO gia_du_doan (MaSP, GiaBanDuDoan) VALUES ('{row['MaSP']}', {row['GiaBanDuDoan']});\\n\"\n",
        "\n",
        "# L∆∞u n·ªôi dung v√†o file .sql\n",
        "ten_file_sql = 'gia_ban_du_doan.sql'\n",
        "with open(ten_file_sql, 'w') as f:\n",
        "    f.write(sql_commands)\n",
        "\n",
        "print(f\"\\nƒê√£ l∆∞u gi√° b√°n d·ª± ƒëo√°n v√†o file SQL: '{ten_file_sql}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afuiCfHew-HD",
        "outputId": "bf3b5189-b00b-4605-e4d1-129533c9727d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gi√° b√°n d·ª± ƒëo√°n cu·ªëi c√πng (d·ª±a tr√™n m√¥ h√¨nh h·ªìi quy t·ª´ t·∫•t c·∫£ c√°c gi√°):\n",
            "    MaSP  GiaBanDuDoan\n",
            "0   SP01     21.948539\n",
            "1   SP02     17.356573\n",
            "2   SP03     25.388889\n",
            "3   SP04     25.644444\n",
            "4   SP05     24.311111\n",
            "5   SP06     23.803872\n",
            "6   SP07     23.900000\n",
            "7   SP08     15.561111\n",
            "8   SP09     16.524169\n",
            "9   SP10     15.483333\n",
            "10  SP11     17.561111\n",
            "11  SP12     14.844444\n",
            "12  SP13     20.688889\n",
            "13  SP14     19.922222\n",
            "14  SP15     20.022222\n",
            "15  SP16     21.050000\n",
            "16  SP17     19.766667\n",
            "17  SP18     22.183333\n",
            "\n",
            "ƒê√£ l∆∞u gi√° b√°n d·ª± ƒëo√°n v√†o file SQL: 'gia_ban_du_doan.sql'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6xS5l6x1w9ma"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}